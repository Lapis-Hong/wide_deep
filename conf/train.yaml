### Train Configuration

## Train & Test Parameters

# Note this part set some defaults to Argparser, these can be override by using command line.
#   For example, `python train.py --model_dir ./model_new`

# model_dir: Model base directory to save model, full model directory = model_dir/model_type.
# model_type: `wide` or `deep` or `wide_deep`.
# dynamic train: Bool, a train mode that first take file1 as train data, file2 as test data;
#     then keep training take file2 as train data, file3 as test data ...
# train_data: Train csv data path.
# eval_data: Evaluation small csv data path.
# test_data: Test data path.
# image_train_data: Optional, set empty to not use.
# image_eval_data: Optional, set empty to not use.
# image_test_data: Optional, set empty to not use.

# train_epochs: Train epochs.
# epochs_per_eval: Evaluating test data per `epochs_per_eval` epochs. Only work for non-dynamic mode
# batch_size: Recommend 25600.
# keep_train: Bool, if 0, remove model_dir, else keep training.
# checkpoint_path: Optional, specify the checkpoint path to eval or pred the model. Use latest checkpoint path if not specified.

# pos_sample_loss_weight: Optional, set to use weight_column (weighted loss) for imbalance samples.
#    typically use value neg_sample_num/total_sample_num
# neg_sample_loss_weight: Optional, set to use weight_column (weighted loss) for imbalance samples.
#    typically use value pos_sample_num/total_sample_num
# multivalue: Bool, set 1 or true for features with multiple values.
# num_examples: Approximate value for total samples number, use this value for shuffle buffer size when training.
# num_parallel_calls: Parallel degree for parsing input data.
train:
  # path related.
  model_dir: ../model
  model_type: wide_deep
  train_data: ../data/train
  eval_data: ../data/eval
  test_data: ../data/test
  image_train_data:
  image_eval_data:
  image_test_data:
  # train behavior
  dynamic_train: false
  train_epochs: 5
  epochs_per_eval: 1
  batch_size: 64
  keep_train: 0
  checkpoint_path:
  # dataset related
  pos_sample_loss_weight: 0.99
  neg_sample_loss_weight: 0.01
  multivalue: 1
  num_examples: 10000
  num_parallel_calls: 48


## Distribution Parameters

# is_distribution: Bool, set 0 for local mode, set 1 for distributed mode.
# cluster: cluster spec.
#   ps: List, parameter server ip list.
#   chief: List, chief worker ip list.
#   worker: List, worker ip list.
# job_name: `ps` or `chief` or `worker`.
# task_index: the host index, start from 0.
distribution:
  is_distribution: 0
  cluster:
    ps: ['10.172.110.162:3333']
    chief: ['10.120.180.212:3333']
    worker: ['10.120.180.213:3333', '10.120.180.214:3333', '10.120.180.215:3333']
  job_name: ps
  task_index: 0

## Runconfig Parameters

# config for `tf.estimator.RunConfig`. See details in https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig
# tf_random_seed: Random seed for TensorFlow initializers. Setting this value allows consistency between reruns.
# save_summary_steps: Save summaries every this many steps. Defaults to 100.
# save_checkpoints_steps: Save checkpoints every this many steps. Can not be specified with save_checkpoints_secs.
# save_checkpoints_secs: Save checkpoints every this many seconds. Can not be specified with save_checkpoints_steps.
#   Defaults to 600 seconds if both save_checkpoints_steps and save_checkpoints_secs are not set in constructor.
#   If both save_checkpoints_steps and save_checkpoints_secs are None, then checkpoints are disabled.
# session_config: a ConfigProto used to set session parameters, or None.
# keep_checkpoint_max: The maximum number of recent checkpoint files to keep. As new files are created, older files are deleted.
#   If None or 0, all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent checkpoint files are kept.)
# keep_checkpoint_every_n_hours: Number of hours between each checkpoint to be saved. The default value of 10,000 hours effectively disables the feature.
# log_step_count_steps: The frequency, in number of global steps, that the global step/sec will be logged during training. Defaults to 100

runconfig:
  tf_random_seed: 123
  save_summary_steps: 1000
  save_checkpoints_steps:
  save_checkpoints_secs: 1800
  keep_checkpoint_max: 5
  keep_checkpoint_every_n_hours: 1
  log_step_count_steps: 1000




